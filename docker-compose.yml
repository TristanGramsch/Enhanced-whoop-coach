version: "3.9"

services:
  orchestrator:
    build:
      context: ./orchestrator
      dockerfile: Dockerfile
    image: hrv_orchestrator:dev
    container_name: hrv_orchestrator
    command: python -u run_pipeline.py
    environment:
      - PYTHONUNBUFFERED=1
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - OUTPUTS_DIR=/app/shared/outputs
    volumes:
      - ./data:/app/data:ro
      - ./shared:/app/shared
      - ./model_training:/app/model_training:ro
      - ./data_intelligence:/app/data_intelligence:ro
      - ./llm_agent:/app/llm_agent:ro
      - ./journal_analysis:/app/journal_analysis:ro
    depends_on:
      - mlflow
    restart: on-failure

  dashboard:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    image: hrv_dashboard:dev
    container_name: hrv_dashboard
    ports:
      - "8501:8501"
    environment:
      - PYTHONUNBUFFERED=1
      - OUTPUTS_DIR=/app/shared/outputs
    depends_on:
      - orchestrator
    volumes:
      - ./data:/app/data:ro
      - ./shared:/app/shared
    restart: unless-stopped

  journal_web:
    build:
      context: ./journal_analysis
      dockerfile: Dockerfile.web
    image: journal_web:dev
    container_name: journal_web
    ports:
      - "8080:8080"
    environment:
      - PYTHONUNBUFFERED=1
      - OUTPUTS_DIR=/app/shared/outputs
    volumes:
      - ./shared:/app/shared
      - ./journal_analysis:/app/journal_analysis:ro
    restart: unless-stopped

  data_intel_api:
    build:
      context: ./data_intelligence
      dockerfile: Dockerfile.api
    image: data_intelligence_api:dev
    container_name: data_intel_api
    ports:
      - "7000:7000"
    environment:
      - PYTHONUNBUFFERED=1
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - OUTPUTS_DIR=/app/shared/outputs
    volumes:
      - ./data:/app/data:ro
      - ./shared:/app/shared
      - ./data_intelligence:/app/data_intelligence:ro
    depends_on:
      - mlflow
    restart: unless-stopped

  whoop_api:
    build:
      context: ./whoop_api_client
      dockerfile: Dockerfile
    image: whoop_api:dev
    container_name: whoop_api
    environment:
      - WHOOP_CLIENT_ID=${WHOOP_CLIENT_ID}
      - WHOOP_CLIENT_SECRET=${WHOOP_CLIENT_SECRET}
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data
      - ./whoop_api_client/token.json:/app/whoop_api_client/token.json
    restart: unless-stopped

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.16.0
    container_name: mlflow
    command: mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri sqlite:///mlflow/mlflow.db --default-artifact-root /mlflow/artifacts
    ports:
      - "5000:5000"
    volumes:
      - ./shared/mlflow:/mlflow
    restart: unless-stopped

  dagster_webserver:
    build:
      context: ./orchestrator
      dockerfile: Dockerfile.dagster
    container_name: dagster_webserver
    ports:
      - "3000:3000"
    volumes:
      - ./data:/app/data:ro
      - ./shared:/app/shared
      - ./model_training:/app/model_training:ro
      - ./data_intelligence:/app/data_intelligence:ro
      - ./llm_agent:/app/llm_agent:ro
      - ./journal_analysis:/app/journal_analysis:ro
      - ./orchestrator/dagster_app:/app/dagster_app
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - OUTPUTS_DIR=/app/shared/outputs
    depends_on:
      - mlflow
    restart: unless-stopped

  dev_agent:
    image: python:3.11
    container_name: dev_agent
    working_dir: /app
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OUTPUTS_DIR=/app/shared/outputs
    volumes:
      - ./shared:/app/shared
      - ./dev_agent:/app/dev_agent:ro
    command: python -u dev_agent/agent.py
    restart: "no"